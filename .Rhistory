colnames(meanStdExpData)
meanStdExpData <- select(expData, contains('mean'), contains('std'),
-contains('angle'), activity, subject)
colnames(meanStdExpData)
colnames(meanStdExpData) <- gsub('...','-',colnames(meanStdExpData))
colnames(meanStdExpData)
meanStdExpData <- select(expData, contains('mean'), contains('std'),
-contains('angle'), activity, subject)
names(meanStdExpData)
sub(".","_",names(meanStdExpData))
as.character(".")
?grep
sub("\.","_",names(meanStdExpData))
sub(\.,"_",names(meanStdExpData))
sub('\.',"_",names(meanStdExpData))
sub('\\.',"_",names(meanStdExpData))
gsub('\\.',"_",names(meanStdExpData))
colnames(meanStdExpData) <- gsub('\\.',"_",colnames(meanStdExpData))
colnames(meanStdExpData)
gsub('___',"_",colnames(meanStdExpData))
?gsub
gsub('___','__',"_",colnames(meanStdExpData))
colnames(meanStdExpData)
gsub(('___','__'),"_",colnames(meanStdExpData))
gsub(('___' | '__'),"_",colnames(meanStdExpData))
gsub('___' | '__',"_",colnames(meanStdExpData))
gsub(regex('___' | '__'),"_",colnames(meanStdExpData))
?regex
regex('___' | '__')
?gregexpr
gsub([_],"_",colnames(meanStdExpData))
gsub([___],"_",colnames(meanStdExpData))
gsub('[___]',"_",colnames(meanStdExpData))
gsub('[_]',"_",colnames(meanStdExpData))
gsub('[_] | [__]',"_",colnames(meanStdExpData))
gsub('[_] | [___]',"_",colnames(meanStdExpData))
gsub('[_+]',"_",colnames(meanStdExpData))
gsub('[_+]',"%",colnames(meanStdExpData))
gsub('[_]',"%",colnames(meanStdExpData))
gsub('[_|__]',"%",colnames(meanStdExpData))
gsub('[_|__]',"_",colnames(meanStdExpData))
gsub('[_|__|__]',"_",colnames(meanStdExpData))
gsub('[_]|[__]|[__]',"_",colnames(meanStdExpData))
gsub('_{3,}',"_",colnames(meanStdExpData))
gsub('_{4,}',"_",colnames(meanStdExpData))
gsub('_{2,}',"_",colnames(meanStdExpData))
gsub('_{1,}',"_",colnames(meanStdExpData))
meanStdExpData <- select(expData, contains('mean'), contains('std'),
-contains('angle'), activity, subject)
gsub('\\.{1,}',"_",colnames(meanStdExpData))
gsub('\\.+',"_",colnames(meanStdExpData))
colnames(meanStdExpData) <- gsub('\\.+',"_",colnames(meanStdExpData))
colnames(meanStdExpData)
gsub('\\_$',"",colnames(meanStdExpData))
gsub('\_$',"",colnames(meanStdExpData))
gsub('_$',"",colnames(meanStdExpData))
?rename
meanStdExpData <- select(expData, contains('mean'), contains('std'),
-contains('angle'), activity, subject)
rename(meanStdExpData, gsub('\\.+',"_",colnames(meanStdExpData) )
rename(meanStdExpData, gsub('\\.+',"_",colnames(meanStdExpData)))
rename(meanStdExpData, gsub('\\.+',"_",names(meanStdExpData)))
?names
names(meanStdExpData)
meanStdExpData <- select(expData, contains('mean'), contains('std'),
-contains('angle'), activity, subject)
# *3* Use descriptive activity names to name the activities in the data set
# Import activity names
activityNames <- read.table(file.path(headDataPath, activityLabelFile),
col.names = c('NULL','activity'),
colClasses = c('NULL','factor'))
# Substitute number with descriptive activity names
levels(meanStdExpData$activity) <- levels(activityNames$activity)
# *4* Appropriately labels the data set with descriptive variable names;
# original feature names seem descriptive enough, but need tidying up
names(meanStdExpData) <- gsub('\\.+',"_",names(meanStdExpData)) %>%
gsub('_$',"",names(meanStdExpData))
names(meanStdExpData)
meanStdExpData <- select(expData, contains('mean'), contains('std'),
-contains('angle'), activity, subject)
# *3* Use descriptive activity names to name the activities in the data set
# Import activity names
activityNames <- read.table(file.path(headDataPath, activityLabelFile),
col.names = c('NULL','activity'),
colClasses = c('NULL','factor'))
# Substitute number with descriptive activity names
levels(meanStdExpData$activity) <- levels(activityNames$activity)
names(meanStdExpData)
gsub('\\.+',"_",names(meanStdExpData))
gsub('\\.+',"_",names(meanStdExpData)) %>%
gsub('_$',"",names())
?gsub
names(meanStdExpData) <- gsub('\\.+',"_",names(meanStdExpData))
names(meanStdExpData) <- gsub('_$',"",names(meanStdExpData))
names(meanStdExpData)
names(meanStdExpData)
averageData <- group_by(meanStdExpData, activity, subject) %>%
summarise_each(funs(mean))
averageData <- group_by(meanStdExpData, subject, activity) %>%
summarise_each(funs(mean))
View(averageData)
averageData <- group_by(meanStdExpData, activity, subject) %>%
summarise_each(funs(mean))
View(averageData)
dim(averageData)
dim(meanStdExpData)
meanStdExpData <- select(expData, contains('mean'), contains('std'),
-contains('angle'), activity, subject)
# *3* Use descriptive activity names to name the activities in the data set
# Import activity names
activityNames <- read.table(file.path(headDataPath, activityLabelFile),
col.names = c('NULL','activity'),
colClasses = c('NULL','factor'))
# Substitute number with descriptive activity names
levels(meanStdExpData$activity) <- levels(activityNames$activity)
# *4* Appropriately labels the data set with descriptive variable names;
# original feature names seem descriptive enough, but need tidying up
names(meanStdExpData) <- gsub('\\.+',"_",names(meanStdExpData))
names(meanStdExpData) <- gsub('_$',"",names(meanStdExpData))
names(meanStdExpData) <- gsub('Body{2}',"Body",names(meanStdExpData))
# *5* From the data set in step 4, create a second, independent tidy data set with
# the average of each variable for each activity and each subject.
averageData <- group_by(meanStdExpData, activity, subject) %>%
summarise_each(funs(mean))
dim(meanStdExpData)
dim(averageData)
names(meanStdExpData)
names(meanStdExpData)
names(meanStdExpData) <- gsub('\\.+','_',names(meanStdExpData))
names(meanStdExpData) <- gsub('_$',"",names(meanStdExpData))
names(meanStdExpData) <- gsub('BodyBody','Body',names(meanStdExpData))
names(meanStdExpData)
names(meanStdExpData)
unique(names(meanStdExpData))
?write_table
?write.table
# Export tidy data frame to Tidy Activity.txt
write_table(averageData, file="Tidy Activity.txt", row.names=FALSE)
# Export tidy data frame to Tidy Activity.txt
write.table(averageData, file="Tidy Activity.txt", row.names=FALSE)
View(averageData)
names(meanStdExpData)
library(dplyr)
library(tidyr)
headDataPath <- file.path(getwd(),'UCI HAR Dataset')
trainDataPath <- file.path(headDataPath, 'train')
testDataPath <- file.path(headDataPath, 'test')
featuresFile <- 'features.txt'
activityLabelFile <- 'activity_labels.txt'
trainXDataFile <- 'X_train.txt'
trainYDataFile <- 'y_train.txt'
trainSubjFile <- 'subject_train.txt'
testXDataFile <- 'X_test.txt'
testYDataFile <- 'y_test.txt'
testSubjFile <- 'subject_test.txt'
# Import feature names
features <- read.table(file.path(headDataPath,featuresFile),
colClasses=c("NULL",'character'),
col.names = c('NULL','features'))
# Function to import data appending X, Y and subject data
importData <- function(dataPath, xDataFile, yDataFile, subjFile, featureNames, designation)
{
# Import X data
xData <- read.table(file.path(dataPath, xDataFile),
col.names = featureNames)
xData <- tbl_df(xData)
# Import Y data
yData <- read.table(file.path(dataPath, yDataFile),
col.names = c('activity'),
colClasses = c('factor'))
yData <- tbl_df(yData)
# Import subject data
subjData <- read.table(file.path(dataPath, subjFile),
col.names = c('subject'))
subjData <- tbl_df(subjData)
# Merge X, Y and Subject training data and add column to designation if train or test
bind_cols(xData, yData, subjData) %>%
mutate(designation = designation)
}
# *1* Merge the training and the test sets to create one data set
trainData <- importData(trainDataPath, trainXDataFile, trainYDataFile,
trainSubjFile, features$features, 'train')
testData <- importData(testDataPath, testXDataFile, testYDataFile,
testSubjFile, features$features, 'test')
expData <- bind_rows(trainData, testData)
# *2* Extract only the measurements on the mean and standard deviation
meanStdExpData <- select(expData, contains('mean'), contains('std'),
-contains('angle'), -contains('meanFreq'), activity, subject)
# *3* Use descriptive activity names to name the activities in the data set
# Import activity names
activityNames <- read.table(file.path(headDataPath, activityLabelFile),
col.names = c('NULL','activity'),
colClasses = c('NULL','factor'))
# Substitute numbers with descriptive activity names
levels(meanStdExpData$activity) <- levels(activityNames$activity)
# *4* Appropriately label the data set with descriptive variable names;
# original feature names seem descriptive enough, but need tidying up
names(meanStdExpData) <- gsub('\\.+','_',names(meanStdExpData)) #Remove dots
names(meanStdExpData) <- gsub('_$',"",names(meanStdExpData))    #Remove trailing underscores
names(meanStdExpData) <- gsub('BodyBody','Body',names(meanStdExpData))  #Remove unnecessary 'Body' repetition
# *5* From the data set in step 4, create a second, independent tidy data set with
# the average of each variable for each activity and each subject.
averageData <- group_by(meanStdExpData, activity, subject) %>%
summarise_each(funs(mean))
names(averageData)
# Export tidy data frame to Tidy Activity.txt
write.table(averageData, file="Tidy Activity.txt", row.names=FALSE)
?read.table
x<- read.table("/Users/Valentin/Documents/Work/Temp/data.txt",skip=3)
x <- tbl_df(x)
x
?"ggplot"
[1:10]
(1:10)
dim(x)
dim(x)[1]
?plot
plot((1:dim(x)[1]),x$V2)
plot((1:dim(x)[1]),x$V2, type = 'l')
(1:dim(x)[1])
plot((1:dim(x)[1]),(1:dim(x)[1]), type = 'l')
ggplot(x,aes(x=(1:dim(x)[1]),y=x$V2)) + geom_line()
ggplot(x,aes(x=(1:dim(x)[1]),y=x$V2)) + geom_points()
ggplot(x,aes(x=(1:dim(x)[1]),y=x$V2)) + geom_point()
x$V2[1:10]
ggplot(x,aes(x=(1:length(x$V2[1:10])),y=x$V2[1:10])) + geom_point()
(1:length(x$V2[1:10])
(1:length(x$V2[1:10]))
x$V2[1:10]
p<- (1:length(x$V2[1:10]))
q<- x$V2[1:10]
ggplot(x,aes(x=p,y=q) + geom_point()
ggplot(x,aes(x=p,y=q)) + geom_point()
q<- x$V2[1:10,2]
q
q<- x[1:10,2]
q
ggplot(x,aes(x=p,y=q)) + geom_point()
plot(q)
?plot
p<-plot(q)
print(p)
x
c(1:10)
p<- c(1:length(x$V2[1:10]))
p
q<- x[1:10,2]
q
plot(q,p)
plot(q,x$V2[1:10])
x$V2[1:10]
class(x$V2[1:10])
is.vector(x$V2[1:10])
is.vector(c(1:10))
plot(c(1:10),x$V2[1:10])
?ggplot
plot(c(1:10),x$V2[1:10],type='l')
clas(c(1:10))
class(c(1:10))
class(x$V2[1:10])
x$V2[1:10]
p=x$V2[1:10]
q=c(1:10)
plot(q,p,type="l")
?x11
graphics.off()
plot(q,p,type="l")
?graphics.off
plot(p)
plot(p,type='l')
plot(x$V1[:,1],type='l')
plot(x$V1,type='l')
dir()
setwd("/Users/Valentin/Documents/Education/Data Science/Getting and Cleaning Data/Quiz3")
?download.file
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile="ACS_data.csv",method='curl')
dir
dir()
ACS_data <- read.csv("ACS_data.csv")
head(ACS_data)
ACS_data <- tbl_df(ACS_data)
ACS_data
str(ACS_data)
ACSdata <- ACS_data
acsData <- ACS_data
str(acsData$ACR)
factor(acsData$ACR)
acsData$ACR == 3
acsData$ACR == 3 & acsData$AGS == 6
agricultureLogical <- (acsData$ACR == 3 & acsData$AGS == 6)
which(agricultureLogical)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", destfile = "pic.jpg",method='curl')
install.package("jpeg")
install.packages("jpeg")
library(jpeg)
browseVignettes((package = jpeg))
browseVignettes(package = 'jpeg')
?jpeg
??jpeg
readJPEG("pic.jpg", native = TRUE)
pic <- readJPEG("pic.jpg", native = TRUE)
summary(pic)
str(pic)
?summary
?quantile
quantile(pic, probs = seq(0.3, 0.8))
seq(0.3, 0.8)
?seq
quantile(pic, probs = seq(0.8))
quantile(pic, probs = seq(0.3))
quantile(pic, probs = 0.3
)
quantile(pic, probs = 0.8)
?quantile
seq(0.3, 0.8)
seq(0.3, 0.9)
seq([0.3, 0.9])
seq(0.25, 0.5)
seq(0.25, 0.5,1)
seq(0, 1, 0.25)
seq(0.3, 0.8, 0.5)
quantile(pic, probs = seq(0.3,0.8,0.5))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile = "GDP.csv", method ='curl')
gdp <- read.csv("GDP.csv")
head(gdp)
gdp <- read.csv("GDP.csv", skip=5)
head(gdp)
gdp <- read.csv("GDP.csv", skip=4)
gdp <- read.csv("GDP.csv", skip=5, head = false)
gdp <- read.table("GDP.csv", skip=5, head = false)
gdp <- read.table("GDP.csv", skip=5, head = FALSE)
gdp <- read.csv("GDP.csv", skip=5, head = FALSE)
head(gdp)
?read.csv
gdp <- read.csv("GDP.csv", skip=3)
head(gdp)
gdp <- read.csv("GDP.csv", skip=3, skipNul = TRUE)
head(gdp)
gdp <- gdp[-c(1)]
head(gdp)
gdp <- read.csv("GDP.csv", skip=3, skipNul = TRUE)
gdp <- gdp[-c(1),]
head(gdp)
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv', destfile = 'education', method='curl')
edu <- read.csv("education.csv")
head(edu)
str(edu)
?match
head(gdp)
gdp$X %in% edu$CountryCode
sum(gdp$X %in% edu$CountryCode)
gdp
head(gdp)
tail(gdp)
which(gdp$X == '')
?read.csv
gdp <- read.table("GDP.csv", sep = ',', skip=5, head = FALSE, nrows = 190)
gdp <- read.csv("GDP.csv",skip=5, head = FALSE, nrows = 190)
head(gdp)
dim(gdp)
sum9gdp$V1 %in% edu$CountryCode)
sum(gdp$V1 %in% edu$CountryCode)
?arrange
arrange(gdp, desc(gdp$V2))
class(gdp$V2)
class(gdp)
tail(gdp)
sum(is.na(gdp$V2))
arrange(gdp, gdp$V2)
arrange(gdp, desc(V2)
)
str(edu)
?merge
newCountryData <- merge(gdp, edu, by.x='V2', by.y='CountryCode')
head(newCountryData)
newCountryData <- tbl_df(newCountryData)
newCounrtyData
newCountryData
newCountryData <- merge(gdp, edu, by.x=V2, by.y=CountryCode)
newCountryData <- merge(gdp, edu, by.x=gdp$V2, by.y=eduCountryCode)
newCountryData <- merge(gdp, edu, by.x=gdp$V2, by.y=edu$CountryCode)
newCountryData <- merge(gdp, edu, by.x=2, by.y=1)
dim(newCountryData)
class(gdp$V2)
factor(gdp$V2)
gdp$V1
class(gdp$V1§)
class(gdp$V1)
newCountryData <- merge(gdp, edu, by.x='V1', by.y='CountryCode')
dim(newCountryData)
newCountryData <- tbl_df(newCountryData)
newCountryData
grou_by(newCountryData, Incom.Group) %>% summarise(mean(V2))
group_by(newCountryData, Incom.Group) %>% summarise(mean(V2))
group_by(newCountryData, Income.Group) %>% summarise(mean(V2))
?cut
?seq
?quantile
quantile(newCountryData$V2,seq(0,1,0.2))
?cut
cut(newCountryData$V2,quantile(newCountryData$V2,seq(0,1,0.2)))
all(is.na(newCountryData$V2))
any(is.na(newCountryData$V2))
newCountryData$V2
newCountryData$V2
newCountryData$V2
cut(newCountryData$V2,quantile(newCountryData$V2,seq(0,1,0.2)))
newCountryData$V2
?cut
cut(newCountryData$V2,quantile(newCountryData$V2,seq(0,1,0.2)),inclue.lowest=TRUE)
?quantile
seq(0,1,0.2)
?seq
seq(0,1,seq_line=5)
seq(0,1,seq_lin=5)
seq(0,1,seq_len=5)
seq(0,1,length.out=5)
seq(0,1,length.out=6)
quantile(newCountryData$V2,seq(0,1,length.out=6))
cut(newCountryData$V2,quantile(newCountryData$V2,seq(0,1,by=0.2)),inclue.lowest=TRUE)
cut(newCountryData$V2,quantile(newCountryData$V2,seq(0,1,by=0.2)),include.lowest=TRUE)
newCountryData
?xtab
install.packages("Hmisc")
library(Hmisc)
?xtabs
?cbind
newCountryData <- cbind(newCountryData, cut(newCountryData$V2,quantile(newCountryData$V2,seq(0,1,by=0.2)),include.lowest=TRUE))
newCountryData
newCountryData <- tbl_df(newCountryData)
newOCUn
newCountryData
newCountryData <- mutate( newCountryData, GDPquantiles = cut(newCountryData$V2,quantile(newCountryData$V2,seq(0,1,by=0.2)),include.lowest=TRUE))
?xtab
?xtabs
xtabs(formula = Income.Group ~ GDPquantiles, newCountryData)
?table
table(newCountryData$Income.Group, newCountryData$GDPquantiles)
rm(list=ls())
sewd("/Users/Valentin/Documents/Education/Data Science/Exploratory Data Analysis/Project 2")
setwd("/Users/Valentin/Documents/Education/Data Science/Exploratory Data Analysis/Project 2")
NEI <- readRDS("summarySCC_PM25.rds")
library(dplyr)
nei <- tbl_df(NEI)
nei
?dcast
NEImelt <-melt(NEI, id=c("year"), measure.vars = c("Emissions"))
library(reshape2)
NEImelt <-melt(NEI, id=c("year"), measure.vars = c("Emissions"))
head(NEImelt)
yearData <- dcast(NEImelt, year ~ variable, sum)
head(yearData)
SCC <- readRDS("Source_Classification_Code.rds")
scc <- tbl_df(SCC)
scc
unique(scc$EI.Sector)
## Picking up the columns that I am interested in (emissions, year)
pollutant <- NEI[, c(4, 6)]
## Subsetting up the emissions by year
year_1999 <- subset(pollutant, year == 1999)
year_2002 <- subset(pollutant, year == 2002)
year_2005 <- subset(pollutant, year == 2005)
year_2008 <- subset(pollutant, year == 2008)
## Summing up the total emissions by year
emissions_sum_1999 <- sum(year_1999$Emissions)
emissions_sum_2002 <- sum(year_2002$Emissions)
emissions_sum_2005 <- sum(year_2005$Emissions)
emissions_sum_2008 <- sum(year_2008$Emissions)
## Creating new data frame of total emissions by year and the years
emissions <-
c(emissions_sum_1999, emissions_sum_2002, emissions_sum_2005, emissions_sum_2008)
year <- c(1999, 2002, 2005, 2008)
data <- data.frame(emissions, year)
## PNG device
# png(filename = "plot1.png", width = 540, height = 540)
plot(
x = data$year, y = data$emissions, xlab = 'Year', ylab = 'Total PM2.5 emitted by year'
)
fit <- lm(emissions~year, data = data)
lines(data$year, fitted(fit), col = "red")
## Write it out
# dev.off()
## Picking up the columns that I am interested in (fips, emissions, year)
pollutant <- NEI[, c(1, 4, 6)]
## Pulling out Baltimore, MD data only
pollutant <- subset(pollutant, fips == "24510")
## Subsetting up the emissions by year
year_1999 <- subset(pollutant, year == 1999)
year_2002 <- subset(pollutant, year == 2002)
year_2005 <- subset(pollutant, year == 2005)
year_2008 <- subset(pollutant, year == 2008)
## Summing up the total emissions by year
emissions_sum_1999 <- sum(year_1999$Emissions)
emissions_sum_2002 <- sum(year_2002$Emissions)
emissions_sum_2005 <- sum(year_2005$Emissions)
emissions_sum_2008 <- sum(year_2008$Emissions)
## Creating new data frame of total emissions by year and the years
emissions <-
c(emissions_sum_1999, emissions_sum_2002, emissions_sum_2005, emissions_sum_2008)
year <- c(1999, 2002, 2005, 2008)
data <- data.frame(emissions, year)
## PNG device
# png(filename = "plot2.png", width = 540, height = 540)
plot(
x = data$year, y = data$emissions, xlab = 'Year', ylab = 'Total PM2.5 emitted by year for Baltimore, Maryland'
)
fit <- lm(emissions~year, data = data)
lines(data$year, fitted(fit), col = "red")
## Write it out
# dev.off()
?revalue
?mapvalues
